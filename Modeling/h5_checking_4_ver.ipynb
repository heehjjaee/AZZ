{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97323764-0d88-4ce1-8351-1d7f5ee61783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x7fa8801f6590>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_img, img_to_array\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 모델 불러오기\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb_model_max.weights.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/mel/100648-1-0-0.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m load_img(img_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m200\u001b[39m))  \u001b[38;5;66;03m# 이미지 로드 및 크기 조정\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39mload_weights_only(\n\u001b[0;32m--> 238\u001b[0m         model, filepath, skip_mismatch\u001b[38;5;241m=\u001b[39mskip_mismatch\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    241\u001b[0m     objects_to_skip \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects_to_skip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.config.is_traceback_filtering_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if traceback filtering is enabled.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Raw Keras tracebacks (also known as stack traces)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    involve many internal frames, which can be\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    challenging to read through, while not being actionable for end users.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    By default, Keras filters internal frames in most exceptions that it\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    raises, to keep traceback short, readable, and focused on what's\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    actionable for you (your own code).\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    See also `keras.config.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    `keras.config.disable_traceback_filtering()`.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    If you have previously disabled traceback filtering via\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    `keras.config.disable_traceback_filtering()`, you can re-enable it via\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    `keras.config.enable_traceback_filtering()`.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        Boolean, `True` if traceback filtering is enabled,\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m        and `False` otherwise.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m global_state\u001b[38;5;241m.\u001b[39mget_global_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback_filtering\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/legacy/hdf5_format.py:194\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x7fa8801f6590>."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('b_model_max.weights.h5')\n",
    "\n",
    "img_path = '/home/jovyan/mel/100648-1-0-0.png'\n",
    "img = load_img(img_path, target_size=(500, 200))  # 이미지 로드 및 크기 조정\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "print(\"Prediction array:\", predict)\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스 출력\n",
    "predicted_index = tf.argmax(predict, axis=1).numpy()[0]\n",
    "print(\"Predicted class index:\", predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fafb944-22bf-4458-9dd7-fde5e8573c71",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 500, 200, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_12'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_img, img_to_array\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 모델 불러오기\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/mel/103074-7-0-0.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m load_img(img_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m200\u001b[39m))  \u001b[38;5;66;03m# 이미지 로드 및 크기 조정\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39mload_weights_only(\n\u001b[0;32m--> 238\u001b[0m         model, filepath, skip_mismatch\u001b[38;5;241m=\u001b[39mskip_mismatch\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    241\u001b[0m     objects_to_skip \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects_to_skip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.config.is_traceback_filtering_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if traceback filtering is enabled.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Raw Keras tracebacks (also known as stack traces)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    involve many internal frames, which can be\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    challenging to read through, while not being actionable for end users.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    By default, Keras filters internal frames in most exceptions that it\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    raises, to keep traceback short, readable, and focused on what's\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    actionable for you (your own code).\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    See also `keras.config.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    `keras.config.disable_traceback_filtering()`.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    If you have previously disabled traceback filtering via\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    `keras.config.disable_traceback_filtering()`, you can re-enable it via\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    `keras.config.enable_traceback_filtering()`.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        Boolean, `True` if traceback filtering is enabled,\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m        and `False` otherwise.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m global_state\u001b[38;5;241m.\u001b[39mget_global_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback_filtering\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:870\u001b[0m, in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 500, 200, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_12'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('b_model.h5')\n",
    "\n",
    "img_path = '/home/jovyan/mel/103074-7-0-0.png'\n",
    "img = load_img(img_path, target_size=(500, 200))  # 이미지 로드 및 크기 조정\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "print(\"Prediction array:\", predict)\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스 출력\n",
    "predicted_index = tf.argmax(predict, axis=1).numpy()[0]\n",
    "print(\"Predicted class index:\", predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a641c3e3-e83c-4c1c-b28e-0624a375e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as ft\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e445545-668b-4f8b-91bd-4ddb6082a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "Prediction array: [[5.0687022e-06 2.5489344e-06 9.9999237e-01 4.6971181e-08]]\n",
      "Predicted class index: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('b_model.h5')\n",
    "\n",
    "img_path = '/home/jovyan/mel/102853-8-0-0.png'\n",
    "img = load_img(img_path, target_size=(500, 200))  # 이미지 로드 및 크기 조정\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "print(\"Prediction array:\", predict)\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스 출력\n",
    "predicted_index = tf.argmax(predict, axis=1).numpy()[0]\n",
    "print(\"Predicted class index:\", predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8022c00c-5a95-495b-9ea8-3d188e1b72fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "Prediction array: [[7.6171663e-20 3.4637225e-15 1.0000000e+00 6.5062983e-18]]\n",
      "Predicted class index: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('b_model.h5')\n",
    "\n",
    "img_path = '/home/jovyan/sirentest.png'\n",
    "img = load_img(img_path, target_size=(500, 200))  # 이미지 로드 및 크기 조정\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "print(\"Prediction array:\", predict)\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스 출력\n",
    "predicted_index = tf.argmax(predict, axis=1).numpy()[0]\n",
    "print(\"Predicted class index:\", predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c363d5d9-4c56-445a-8ac0-df7b9b82e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 23:44:57.434307: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 23:44:57.498476: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 23:44:58.995104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-31 23:45:01.328354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.378740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.380757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.386811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.388793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.390701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.629603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.631676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.633602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 23:45:01.635514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1523 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:09.0, compute capability: 7.5\n",
      "2024-07-31 23:45:03.041139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 500ms/step\n",
      "Prediction array: [[1.6265657e-27 7.4417818e-23 1.4984491e-22 1.0000000e+00]]\n",
      "Predicted class index: 3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('b_model.h5')\n",
    "\n",
    "img_path = '/home/jovyan/mel/0babycry-10-.png'\n",
    "img = load_img(img_path, target_size=(500, 200))  # 이미지 로드 및 크기 조정\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "print(\"Prediction array:\", predict)\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스 출력\n",
    "predicted_index = tf.argmax(predict, axis=1).numpy()[0]\n",
    "print(\"Predicted class index:\", predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708abe0e-f44a-405a-938b-5beb0366a9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "Prediction array: [[9.4163975e-14 9.7098207e-04 9.9555570e-01 3.4732637e-03]]\n",
      "Predicted class index: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('b_model.h5')\n",
    "\n",
    "img_path = '/home/jovyan/babytest.png'\n",
    "img = load_img(img_path, target_size=(500, 200))  # 이미지 로드 및 크기 조정\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "print(\"Prediction array:\", predict)\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스 출력\n",
    "predicted_index = tf.argmax(predict, axis=1).numpy()[0]\n",
    "print(\"Predicted class index:\", predicted_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
